{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ltA9pmR2xVW"
      },
      "source": [
        "# SLAF-based Privacy-Preserving CNN1 with Homomorphic Encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So_6CkP6bRdz"
      },
      "outputs": [],
      "source": [
        "!pip install tenseal\n",
        "!pip install torch torchvision\n",
        "!pip install matplotlib\n",
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxBQhxzDbS0L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "from torchvision import datasets\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.nn.utils.fusion import fuse_conv_bn_eval\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzC7IYgB2j6t"
      },
      "source": [
        "# MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUp1PPxFbUOn"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(73)\n",
        "\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "classes = train_loader.dataset.classes\n",
        "onecycle=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LdPPHamSnfx"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nCJ0oFoiIRm"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Htme6CkwkU8"
      },
      "source": [
        "**IMPORTANT. Only run one model; testing process will be done on the last model to run!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGVhvmDVlJxS"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gracKLj1iM3K"
      },
      "outputs": [],
      "source": [
        "def sign(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "  elif x < 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "x = np.linspace(-1,1,1000)\n",
        "z = np.arange(-1, 1, .01)\n",
        "y = np.sign(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmXhxs2dbVwh"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rabyyg8oKFCU"
      },
      "source": [
        "## CNN1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKJJIKTDjFC-"
      },
      "source": [
        "### CNN1-ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1 with original ReLU function"
      ],
      "metadata": {
        "id": "GBk29BFztD15"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SklT_NkKQTM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "onecycle=1\n",
        "check = []\n",
        "check2 = []\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        #Collect activation inputs\n",
        "        check.append(torch.max(torch.abs(x.data)))\n",
        "        if torch.max(torch.abs(x.data)) > check[0]:\n",
        "          check[0] = torch.max(torch.abs(x.data))\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        check2.append(torch.max(torch.abs(x.data)))\n",
        "        if torch.max(torch.abs(x.data)) > check2[0]:\n",
        "          check2[0] = torch.max(torch.abs(x.data))\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "summary(net, (1, 28, 28))\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n",
        "    net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUM2gqaji-A2"
      },
      "source": [
        "### CNN1-X^2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1 model using x^2 as activation function"
      ],
      "metadata": {
        "id": "SR61-GFCtsaS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz_oIvOuZ6m7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "onecycle=1\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = x * x\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = x * x\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "summary(net, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aZr4RFadhL"
      },
      "source": [
        "### CNN1-SLAF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1 model using SLAF"
      ],
      "metadata": {
        "id": "7wZIb410t2bY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUvZ7Au_Z8Uz",
        "outputId": "868771a5-de2c-4748-910e-809e5c214f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 4, kernel_size=(7, 7), stride=(3, 3))\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (slu): soft_poly()\n",
            "  (cslu): conv_soft_poly()\n",
            ")\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                setattr(self, \"alpha\" + str(i), torch.nn.Parameter(torch.zeros(1)))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                setattr(self, \"alpha\" + str(i), torch.nn.Parameter(torch.zeros(1)))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 4, 8, 8)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "def getPolyVal(x, coeffs):\n",
        "        curVal = 0\n",
        "        for curValIndex in range(len(coeffs)):\n",
        "            curVal=curVal+(coeffs[curValIndex]*x)\n",
        "        return curVal\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = self.slu(x, 64)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = ConvNet()\n",
        "print(net)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n",
        "\n",
        "    net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26HFeBlYf6cU"
      },
      "source": [
        "### CNN1-SLAF-R"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Train CNN with ReLU (above)\n",
        "2. Re-train with SLAF-R; weights are fixed using requires_grad = False\n",
        "3. Collapse retrained model\n",
        "4. Test collapsed model"
      ],
      "metadata": {
        "id": "jo3cIdRjsjLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AodaE57Ff6F7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # initialize alphai\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 4, 8, 8, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        for param in self.conv1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        for param in self.fc1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "        for param in self.fc2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = self.slu(x, 64)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net_dos.to(device)\n",
        "\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MLuxtlXNlJA"
      },
      "outputs": [],
      "source": [
        "print(dict(net.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG5347PQfm8d"
      },
      "outputs": [],
      "source": [
        "# To recover the saved model for re-training SLAF\n",
        "PATH = './mnist_net.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grjeqnznmZQh"
      },
      "source": [
        "### CNN1-SLAF-P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhpLQm6Imv_Z"
      },
      "source": [
        "Polynomial Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "r59s0C8gmYma",
        "outputId": "02964800-e482-44a1-89b3-bac3fb340c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APROXIMANDO POR LEAST SQUARES ....\n",
            "[ 4.68750043e-04  9.37500046e-02 -1.21527811e-06 -8.10185410e-05]\n",
            "ESCRIBIENDO EN F1 y CONV ....\n",
            "            3             2\n",
            "-8.102e-05 x - 1.215e-06 x + 0.09375 x + 0.0004688\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2b33ef2b50>]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "GRADO = 3\n",
        "\n",
        "def sign(x_my):\n",
        "  if x_my > 0:\n",
        "    return 1\n",
        "  elif x_my < 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def comparison(enc_x):\n",
        "    return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "z_my = np.arange(-30, 30, 0.01)\n",
        "y_my = np.sign(z_my)\n",
        "\n",
        "LEAST_SQUARES = 0\n",
        "COMPOSITION = 1\n",
        "CHEBYSHEV = 2\n",
        "NEWTHON = 3\n",
        "FOURIER = 4\n",
        "\n",
        "SELECTION = LEAST_SQUARES\n",
        "\n",
        "if SELECTION == LEAST_SQUARES:\n",
        "    print(\"APPROXIMATING BY LEAST SQUARES ....\")\n",
        "    polynomial = np.polyfit(z_my, y_my, GRADO)\n",
        "    polynomial = polynomial[::-1]\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 AND CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i].tolist()) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i].tolist()) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "elif SELECTION == CHEBYSHEV:\n",
        "    print(\"APPROXIMATING BY CHEBYSHEV\")\n",
        "    if GRADO == 3:\n",
        "        polynomial = [0, (7/3)*(1/30), 0, -(4/3)*(1/27000)]\n",
        "    else:\n",
        "        polynomial = [0, 1.2797, 0, -0.4444, 0, 0.2901 ,0, -0.2365, 0, 0.1111]\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 AND CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "elif SELECTION == COMPOSITION:\n",
        "    print(\"APPROXIMATING BY COMPOSITION ....\")\n",
        "    if GRADO == 3:\n",
        "        polynomial = [0, (2126/1024), 0, (-1359/1024)]\n",
        "        polynomial = [0, (2126/1024)*(1/30), 0, (-1359/1024)*(1/27000)]\n",
        "    else:\n",
        "        f = np.poly1d([(-1/2), 0, (3/2),0])\n",
        "        g = np.poly1d([(-1359/1024), 0, (2126/1024),0])\n",
        "        polynomial = f(g)\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 AND CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "elif SELECTION == NEWTHON:\n",
        "    print(\"APPROXIMATING BY NEWTON ....\")\n",
        "    polynomial = [0, (3/2)*(1/30), 0, (-1/2)*(1/27000)]\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 AND CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "## GRAPH THE POLYNOMIAL\n",
        "f = open('conv.txt', 'r')\n",
        "list_take=[]\n",
        "\n",
        "for i in range(GRADO + 1):\n",
        "    take = float(f.readline().replace('[','').replace(']',''))\n",
        "    list_take.append(take)\n",
        "f.close()\n",
        "\n",
        "list_take.reverse()\n",
        "poly_ = np.poly1d(list_take)\n",
        "print(poly_)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "poly_ff = [np.polyval(poly_, i) for i in z_my]\n",
        "\n",
        "ax.plot(z_my, poly_ff)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1 model using SLAF-P"
      ],
      "metadata": {
        "id": "33QFAa075lPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAMoPjZKpOAg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64))\n",
        "        else:\n",
        "            f = open('f1.txt', 'r')\n",
        "            for i in range(alpha + 1):\n",
        "                next_value = float(f.readline().replace('[','').replace(']',''))\n",
        "                setattr(self, \"alpha\" + str(i), torch.tensor(next_value))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "            f.close()\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64))\n",
        "        else:\n",
        "            f = open('conv.txt', 'r')\n",
        "            for i in range(alpha + 1):\n",
        "                next_value = float(f.readline().replace('[','').replace(']',''))\n",
        "                setattr(self, \"alpha\" + str(i), torch.tensor(next_value))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "            f.close()\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 4, 8, 8)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        for param in self.conv1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        for param in self.fc1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "        for param in self.fc2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        #ReLU using equivalence with sign\n",
        "        x = (x + x*self.cslu(x))/2\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = (x + x*self.slu(x, 64))/2\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_G_rNm0zOiP"
      },
      "outputs": [],
      "source": [
        "print(net_dos.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq0CJNG9fK1X"
      },
      "outputs": [],
      "source": [
        "# To recover the saved model for retraining SLAF-P, i.e., CNN1-SLAF-P-R\n",
        "PATH = './mnist_net.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42OBesPJbPsU"
      },
      "source": [
        "## One-Cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qwgn0y918Cxu"
      },
      "outputs": [],
      "source": [
        "def find_lr(model, optimiser, start_val = 1e-6, end_val = 1, beta = 0.99, loader = train_loader):\n",
        "    n = len(loader) - 1\n",
        "    factor = (end_val / start_val)**(1/n)\n",
        "    lr = start_val\n",
        "    optimiser.param_groups[0]['lr'] = lr\n",
        "    avg_loss, loss, acc = 0., 0., 0.\n",
        "    lowest_loss = 0.\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "    accuracies = []\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = model.to(device=device)\n",
        "    for i, (x, y) in enumerate(loader, start=1):\n",
        "        x = x.to(device = device, dtype = torch.float32)\n",
        "        y = y.to(device = device, dtype = torch.long)\n",
        "        optimiser.zero_grad()\n",
        "        scores = model(x)\n",
        "        cost = F.cross_entropy(input=scores, target=y)\n",
        "        loss = beta*loss + (1-beta)*cost.item()\n",
        "\n",
        "        avg_loss = loss/(1 - beta**i)\n",
        "\n",
        "        acc_ = ((torch.argmax(scores, dim=1) == y).sum()/scores.size(0))\n",
        "        if i > 1 and avg_loss > 4 * lowest_loss:\n",
        "            print(f'from here{i, cost.item()}')\n",
        "            return log_lrs, losses, accuracies\n",
        "        if avg_loss < lowest_loss or i == 1:\n",
        "            lowest_loss = avg_loss\n",
        "\n",
        "        accuracies.append(acc_.item())\n",
        "\n",
        "        losses.append(avg_loss)\n",
        "        log_lrs.append(lr)\n",
        "\n",
        "        cost.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        print(f'cost:{cost.item():.4f}, lr: {lr:.4f}, acc: {acc_.item():.4f}')\n",
        "        lr *= factor\n",
        "        optimiser.param_groups[0]['lr'] = lr\n",
        "\n",
        "    return log_lrs, losses, accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmUFNjUvBGYW"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvsZTL5sZLS8"
      },
      "outputs": [],
      "source": [
        "#ADAM\n",
        "import torch.optim as optim\n",
        "onecycle = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoJiuuLSjusD",
        "outputId": "bbbc7b9b-de0a-4001-80f5-30d71ae967e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With One-Cycle\n"
          ]
        }
      ],
      "source": [
        "#SGD with One-cycle\n",
        "import torch.optim as optim\n",
        "onecycle =1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if onecycle==1:\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.95, weight_decay=1e-4)\n",
        "  print(\"With One-Cycle\")\n",
        "else:\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "  print(\"Without One-Cycle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1AgjrhBThOB"
      },
      "outputs": [],
      "source": [
        "lg_lr, losses, accuracies = find_lr(net, optimizer, start_val=1e-6, end_val=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rLR3-v3Uq5P"
      },
      "outputs": [],
      "source": [
        "f1, ax1 = plt.subplots(figsize=(20,10))\n",
        "ax1.plot(lg_lr, losses)\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_xticks([1e-1, 2e-1, 1, 10])\n",
        "ax1.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRPIwEW_cHj4"
      },
      "outputs": [],
      "source": [
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
        "                                                max_lr=2e-1,\n",
        "                                                steps_per_epoch=len(train_loader),\n",
        "                                                epochs = 30, pct_start=0.43,\n",
        "                                                div_factor=10,\n",
        "                                                final_div_factor=1000,\n",
        "                                                three_phase=True, verbose=False\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UQSU_TaRAKU",
        "outputId": "1cc5e8c2-446d-4c28-f881-aa3c181203d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVFn0PiEhy4W"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs=30):\n",
        "    model.train()\n",
        "\n",
        "    if onecycle == 1:\n",
        "      print(\"With One-Cycle\")\n",
        "    else:\n",
        "      print(\"Without One-Cycle\")\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        correct_new = 0\n",
        "        total_new = 0\n",
        "        for data, target in train_loader:\n",
        "            if torch.cuda.is_available():\n",
        "              data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total_new += target.size(0)\n",
        "            correct_new += (predicted == target).sum().item()\n",
        "\n",
        "            #One-cycle\n",
        "            if onecycle == 1:\n",
        "              scheduler.step()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        acc_new = 100 * correct_new / total_new\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tCorrect: {} \\tAccuracy: {:.3f}'.format(epoch, train_loss, correct_new, acc_new))\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZY66ulZiIbW"
      },
      "outputs": [],
      "source": [
        "net = train(net, train_loader, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ7y3aIVtAhp"
      },
      "outputs": [],
      "source": [
        "#Save the model for re-training\n",
        "PATH = './mnist_net_.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6fblbIaOa6r"
      },
      "outputs": [],
      "source": [
        "print(check[0])\n",
        "print(check2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSdXvXSlkASy"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp4lNby6kmtO"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuVYhA5UkrDl"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC7nM-1uaay9"
      },
      "source": [
        "## Plaintext testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1f9Xys_Yfyl"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    model.eval()\n",
        "    j = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prQm_gm2ZdRk"
      },
      "outputs": [],
      "source": [
        "t_start = time()\n",
        "test(net, test_loader, criterion)\n",
        "t_end = time()\n",
        "t_total = (t_end - t_start)*1000\n",
        "print(t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOukZgWaDmgq"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'{classname:5s} is {accuracy:.2f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAMRNOnKkim5"
      },
      "source": [
        "# Ciphertext testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYVJmeSamzHh"
      },
      "source": [
        "COPY F1 and CONV1 to ciphertext files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJzKqqdGTBMA"
      },
      "source": [
        "# CNN1-HE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtF8yRGFkqBe"
      },
      "source": [
        "## CNN1-HE-X^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uEGMggWkhrX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "It's a PyTorch-like model using operations implemented in TenSEAL.\n",
        "    - .mm() method is doing the vector-matrix multiplication explained above.\n",
        "    - you can use + operator to add a plain vector as a bias.\n",
        "    - .conv2d_im2col() method is doing a single convlution operation.\n",
        "    - .square_() just square the encrypted vector inplace.\n",
        "\"\"\"\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "\n",
        "    def forward(self, enc_x, windows_nb):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        enc_output = enc_model(x_enc, windows_nb)\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = net.conv1.kernel_size\n",
        "stride = net.conv1.stride[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfduYRbJk2Zm"
      },
      "outputs": [],
      "source": [
        "# Encryption Parameters\n",
        "\n",
        "# Controls precision of the fractional part\n",
        "bits_scale = 26\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
        ")\n",
        "# Set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "# Galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIOUN-fik43n"
      },
      "outputs": [],
      "source": [
        "enc_model = EncConvNet(net)\n",
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_HW0hwA6oG"
      },
      "source": [
        "## CNN1-HE-SLAF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4AnJh9wB6fx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class enc_conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context, torch.zeros(1, device = device))\n",
        "        f = open('t_conv.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            ar_al = ar_al + (x**i)*t[i]\n",
        "        return ar_al\n",
        "\n",
        "class enc_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context,torch.zeros(1, device=device))\n",
        "        f = open('t_f1.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = (x**i) * t[i]\n",
        "            ar_al = ar_al + temp\n",
        "        return ar_al\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "        self.slu = enc_soft_poly(64, alpha=3)\n",
        "        self.cslu = enc_conv_soft_poly(10, alpha=3)\n",
        "\n",
        "    def forward(self, enc_x, windows_nb, context):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        enc_x = self.cslu(enc_x, context)\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        enc_x = self.slu(enc_x,  context)\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride, prog):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    j = 0\n",
        "    n_n = [0] * 10000\n",
        "    n_n_d = [0] * 10000\n",
        "    for data, target in test_loader:\n",
        "        j = j + 1\n",
        "        start_time = time.time()\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        start_time = time.time()\n",
        "        enc_output = enc_model(x_enc, windows_nb, context)\n",
        "        n_n[j-1] = (time.time() - start_time)\n",
        "        print(\"only one test time: \",\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "        n_n_d[j-1] = (time.time() - start_time)\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "    #Original indicates as j-1\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test without decrypt \") + str(i) + str(\" time: : \") + str(n_n[i]) + str('\\n'))\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test with decrypt \") + str(i) + str(\" time: : \") + str(n_n_d[i]) + str('\\n'))\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "        prog.write(str( f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% ') + str(f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'))\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "    prog.write(str( f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ') + str(f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'))\n",
        "\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = net.conv1.kernel_size\n",
        "stride = net.conv1.stride[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIQVVHR-HM5j"
      },
      "outputs": [],
      "source": [
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=16384,\n",
        "    coeff_mod_bit_sizes=[40, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 40]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axcuo-6XBLAo"
      },
      "outputs": [],
      "source": [
        "enc_model = EncConvNet(net)\n",
        "\n",
        "prog = open('tests.txt', 'w', encoding='utf-8')\n",
        "start_time = time.time()\n",
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride, prog)\n",
        "print(\"full time process: \",\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "prog.write(str(\"full time process: \") + str((time.time() - start_time)))\n",
        "prog.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYsHcwaIyM1P"
      },
      "source": [
        "## CNN1-HE-SLAF (with ReLU = x + x * sign(x)*/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ7LWFcuwkVD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class enc_conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context, torch.zeros(1, device = device))\n",
        "        f = open('t_conv.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            ar_al = ar_al + (x**i)*t[i]\n",
        "        return ar_al\n",
        "\n",
        "class enc_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context,torch.zeros(1, device=device))\n",
        "        f = open('t_f1.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = (x**i) * t[i]\n",
        "            ar_al = ar_al + temp\n",
        "        return ar_al\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "        self.slu = enc_soft_poly(64, alpha=3)\n",
        "        self.cslu = enc_conv_soft_poly(10, alpha=3)\n",
        "        self.dos_plaintext = [0.5] * 256\n",
        "        self.dos_plaintext_ = [0.5] * 64\n",
        "\n",
        "    def forward(self, enc_x, windows_nb, context):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        #enc_x = self.cslu(enc_x, context)\n",
        "        enc_x = (enc_x + enc_x * self.cslu(enc_x, context)) * self.dos_plaintext\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        #enc_x = self.slu(enc_x,  context)\n",
        "        enc_x = (enc_x + enc_x * self.slu(enc_x,  context)) * self.dos_plaintext_\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride, prog):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    j = 0\n",
        "    n_n = [0] * 10000\n",
        "    n_n_d = [0] * 10000\n",
        "    for data, target in test_loader:\n",
        "        j = j + 1\n",
        "        start_time = time.time()\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        start_time = time.time()\n",
        "        enc_output = enc_model(x_enc, windows_nb, context)\n",
        "        n_n[j-1] = (time.time() - start_time)\n",
        "        print(\"only one test time: \",\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "        n_n_d[j-1] = (time.time() - start_time)\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test without decrypt \") + str(i) + str(\" time: : \") + str(n_n[i]) + str('\\n'))\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test with decrypt \") + str(i) + str(\" time: : \") + str(n_n_d[i]) + str('\\n'))\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "        prog.write(str( f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% ') + str(f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'))\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "    prog.write(str( f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ') + str(f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'))\n",
        "\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = net.conv1.kernel_size\n",
        "stride = net.conv1.stride[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9K-vM10Zp_H"
      },
      "outputs": [],
      "source": [
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=16384,\n",
        "    coeff_mod_bit_sizes=[35,bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 35]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAIpGcOs68Ok"
      },
      "outputs": [],
      "source": [
        "## New Encryption Parameters\n",
        "bits_scale = 25\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=16384,\n",
        "        coeff_mod_bit_sizes=[40,bits_scale,bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 40]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2GNj4trMWqt"
      },
      "outputs": [],
      "source": [
        "enc_model = EncConvNet(net)\n",
        "\n",
        "prog = open('tests.txt', 'w', encoding='utf-8')\n",
        "start_time = time.time()\n",
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride, prog)\n",
        "print(\"full time process: \",\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "prog.write(str(\"full time process: \") + str((time.time() - start_time)))\n",
        "prog.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}