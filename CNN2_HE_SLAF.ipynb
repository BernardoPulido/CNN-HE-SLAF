{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ltA9pmR2xVW"
      },
      "source": [
        "# SLAF-based Privacy-Preserving CNN2 with Homomorphic Encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So_6CkP6bRdz"
      },
      "outputs": [],
      "source": [
        "!pip install tenseal\n",
        "!pip install torch torchvision\n",
        "!pip install matplotlib\n",
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxBQhxzDbS0L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "from torchvision import datasets\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.nn.utils.fusion import fuse_conv_bn_eval\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzC7IYgB2j6t"
      },
      "source": [
        "# MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUp1PPxFbUOn"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(73)\n",
        "\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "classes = train_loader.dataset.classes\n",
        "onecycle=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LdPPHamSnfx"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nCJ0oFoiIRm"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gracKLj1iM3K"
      },
      "outputs": [],
      "source": [
        "def sign(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "  elif x < 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "x = np.linspace(-1,1,1000)\n",
        "z = np.arange(-1, 1, .01)\n",
        "y = np.sign(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmXhxs2dbVwh"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuAZv4lsax4T"
      },
      "source": [
        "## CNN2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and testing will be carried out on the last model that is executed."
      ],
      "metadata": {
        "id": "ov2aBtlT_QcX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE4Xkcwzgzq9"
      },
      "source": [
        "### CNN2-ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKzySEPhq4cP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "onecycle=1\n",
        "check = []\n",
        "check2 = []\n",
        "check_fn = []\n",
        "check_fn2 = []\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 1)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.batch1 = nn.BatchNorm2d(20)\n",
        "        self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 0)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        self.fc1 = nn.Linear(200, 100)\n",
        "        self.batch2 = nn.BatchNorm1d(100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        #collect activation inputs\n",
        "        if not self.training:\n",
        "          check_fn.append(x.data)\n",
        "        check.append(torch.max(torch.abs(x.data)))\n",
        "        if torch.max(torch.abs(x.data)) > check[0]:\n",
        "          check[0] = torch.max(torch.abs(x.data))\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.batch2(x)\n",
        "        if not self.training:\n",
        "          check_fn2.append(x.data)\n",
        "        check2.append(torch.max(torch.abs(x.data)))\n",
        "        if torch.max(torch.abs(x.data)) > check2[0]:\n",
        "          check2[0] = torch.max(torch.abs(x.data))\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "summary(net, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m7SI6B3lXc8"
      },
      "source": [
        "### CNN2-SLAF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdiakGw0lmpk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "size_due_padding = 13\n",
        "input_due_padding = 200\n",
        "padding_conv1 = 1\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True) # set requiresGrad to true!\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, size_due_padding, size_due_padding, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, padding_conv1)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.batch1 = nn.BatchNorm2d(20)\n",
        "        self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 0)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        self.fc1 = nn.Linear(input_due_padding, hidden)\n",
        "        self.batch2 = nn.BatchNorm1d(100)\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.batch2(x)\n",
        "        x = self.slu(x, 100)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = ConvNet()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net.to(device)\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oshBeB_HxWaM"
      },
      "source": [
        "#### Collapsing linear layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the combination of linear operations is linear and there is no intervening non-linearity between the first pooling layer and the first fully-connected layer of CNN2, the hidden layers between them can be collapsed into a single linear layer for the testing process.\n",
        "\n",
        "Therefore, after each CNN2 model, several cells are incorporated to collapse linear layers, fuse convolutional and batch normalization layers, and generate a collapsed model for evaluation."
      ],
      "metadata": {
        "id": "XEiNbNXM-kXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ijbf_hzNxWCd"
      },
      "outputs": [],
      "source": [
        "_ = torch.manual_seed (2023)\n",
        "# shape of intermediate \"input\" image\n",
        "in_channels = 20\n",
        "h = size_due_padding\n",
        "w = h\n",
        "\n",
        "#convolution parameters\n",
        "out_channels = 50\n",
        "kernel = 5\n",
        "stride = 1\n",
        "\n",
        "#fc paramaters\n",
        "in_features=int (out_channels * (((h - kernel) / 2) + 1)**2)\n",
        "in_features= input_due_padding\n",
        "out_features = 100\n",
        "\n",
        "#LAYERS DEFINITION\n",
        "#conv2 = torch.nn.Conv2d (in_channels, out_channels, kernel, stride)\n",
        "#fc1 = torch.nn.Linear (in_features, out_features)\n",
        "pool1 = nn.AvgPool2d(3, stride=2, padding=1) ##!!!!!!!!!!!!\n",
        "\n",
        "conv2 = net.conv2\n",
        "fc1 = net.fc1\n",
        "batch = net.batch2\n",
        "\n",
        "# create collapsed bias from conv2 and fc1\n",
        "bias = fc1 (torch.flatten (pool1(conv2 (pool1(torch.zeros (1, in_channels, h, w))))))\n",
        "bias = ((torch.sub(bias, batch.running_mean))/torch.sqrt(torch.add(batch.running_var, batch.eps))) * batch.weight + batch.bias\n",
        "\n",
        "# create collapsed weight from conv2 and fc1 (and bias)\n",
        "# batch of images, each with only a single pixel turned on\n",
        "n_pixels = in_channels * h * w   # number of pixels (including channels) in input image\n",
        "pixel_batch = torch.eye (n_pixels).reshape (n_pixels, in_channels, h, w)\n",
        "weight = (batch(fc1 (torch.flatten (pool1(conv2 (pool1(pixel_batch))), 1))) - bias).T\n",
        "\n",
        "# create collapsed Linear\n",
        "fcnew = torch.nn.Linear (n_pixels, out_features)   # Linear of correct shape\n",
        "\n",
        "# copy in collapsed weight and bias\n",
        "with torch.no_grad():\n",
        "  _ = fcnew.weight.copy_ (weight)\n",
        "  _ = fcnew.bias.copy_ (bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0TUhiSaxX8s"
      },
      "source": [
        "#### Fusing convolutional and batch normalization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK6yYPjUxYJN"
      },
      "outputs": [],
      "source": [
        "def fuse_all_conv_bn(model):\n",
        "    stack = []\n",
        "    for name, module in model.named_children():\n",
        "        if list(module.named_children()):\n",
        "            fuse_all_conv_bn(module)\n",
        "\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            if isinstance(stack[-1][1], nn.Conv2d):\n",
        "                setattr(model, stack[-1][0], fuse_conv_bn_eval(stack[-1][1], module))\n",
        "                setattr(model, name, nn.Identity())\n",
        "        else:\n",
        "            stack.append((name, module))\n",
        "\n",
        "net.eval()\n",
        "fuse_all_conv_bn(net)\n",
        "\n",
        "PATH = './mnist_net_collapsed.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhkYM1XyxuNV"
      },
      "source": [
        "#### Collapsed SLAF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfuV4Eavxxqs",
        "outputId": "2e02fef8-7e4c-4214-bcda-90812501d9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "  (fcnew): Linear(in_features=3380, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (slu): soft_poly()\n",
            "  (cslu): conv_soft_poly()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # initialize alphai\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, size_due_padding, size_due_padding, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, padding_conv1)\n",
        "        self.fcnew = nn.Linear(3380, hidden)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          _ = self.fcnew.weight.copy_ (weight)\n",
        "          _ = self.fcnew.bias.copy_ (bias)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fcnew(x)\n",
        "        x = self.slu(x, 100)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwUElEhx7ir"
      },
      "source": [
        "#### Weights control commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD9jvfZ9x8Zz"
      },
      "outputs": [],
      "source": [
        "print(dict(net_dos.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZp-z-VHx8gc"
      },
      "outputs": [],
      "source": [
        "print(net_dos.fcnew.weight.data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2mT2WrHx8lC"
      },
      "outputs": [],
      "source": [
        "# Recover weights for collapsed model!\n",
        "PATH = './mnist_net_collapsed.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3t-j1yCg3Cs"
      },
      "source": [
        "### CNN1-SLAF-R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnTH1GLMWvRO"
      },
      "source": [
        "1. Train CNN with ReLU (see above)\n",
        "2. Re-train with SLAF-R; weights are fixed using requires_grad = False\n",
        "3. Collapse retrained model\n",
        "4. Test collapsed model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0nncL12g6Rs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # initialize alphai\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, 13, 13, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 1)\n",
        "        for param in self.conv1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.batch1 = nn.BatchNorm2d(20)\n",
        "        for param in self.batch1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 0)\n",
        "        for param in self.conv2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc1 = nn.Linear(200, hidden)\n",
        "        for param in self.fc1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.batch2 = nn.BatchNorm1d(100)\n",
        "        for param in self.batch2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        for param in self.fc2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.batch2(x)\n",
        "        x = self.slu(x, 100)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net_dos.to(device)\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOsJ9j9DtEIz"
      },
      "outputs": [],
      "source": [
        "print(dict(net.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBlZQOCDtCMj"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFzl_ax3Ms5N"
      },
      "source": [
        "#### Collapsing linear layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACCiZL9JMs5O"
      },
      "outputs": [],
      "source": [
        "_ = torch.manual_seed (2023)\n",
        "# shape of intermediate \"input\" image\n",
        "in_channels = 20\n",
        "h = 13\n",
        "w = h\n",
        "\n",
        "#convolution parameters\n",
        "out_channels = 50\n",
        "kernel = 5\n",
        "stride = 1\n",
        "\n",
        "#fc paramaters\n",
        "in_features=int (out_channels * (((h - kernel) / 2) + 1)**2)\n",
        "in_features= 200\n",
        "out_features = 100\n",
        "\n",
        "#LAYERS DEFINITION\n",
        "#conv2 = torch.nn.Conv2d (in_channels, out_channels, kernel, stride)\n",
        "#fc1 = torch.nn.Linear (in_features, out_features)\n",
        "pool1 = nn.AvgPool2d(3, stride=2, padding=1) ##!!!!!!!!!!!!\n",
        "\n",
        "conv2 = net.conv2\n",
        "fc1 = net.fc1\n",
        "batch = net.batch2\n",
        "\n",
        "# create collapsed bias from conv2 and fc1\n",
        "bias = fc1 (torch.flatten (pool1(conv2 (pool1(torch.zeros (1, in_channels, h, w))))))\n",
        "bias = ((torch.sub(bias, batch.running_mean))/torch.sqrt(torch.add(batch.running_var, batch.eps))) * batch.weight + batch.bias\n",
        "\n",
        "# create collapsed weight from conv2 and fc1 (and bias)\n",
        "# batch of images, each with only a single pixel turned on\n",
        "n_pixels = in_channels * h * w   # number of pixels (including channels) in input image\n",
        "pixel_batch = torch.eye (n_pixels).reshape (n_pixels, in_channels, h, w)\n",
        "weight = (batch(fc1 (torch.flatten (pool1(conv2 (pool1(pixel_batch))), 1))) - bias).T\n",
        "\n",
        "# create collapsed Linear\n",
        "fcnew = torch.nn.Linear (n_pixels, out_features)   # Linear of correct shape\n",
        "\n",
        "# copy in collapsed weight and bias\n",
        "with torch.no_grad():\n",
        "  _ = fcnew.weight.copy_ (weight)\n",
        "  _ = fcnew.bias.copy_ (bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgF4VCWpxHzM"
      },
      "source": [
        "#### Fusing convolutional and batch normalization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lwKSn7FxZZ0"
      },
      "outputs": [],
      "source": [
        "def fuse_all_conv_bn(model):\n",
        "    stack = []\n",
        "    for name, module in model.named_children():\n",
        "        if list(module.named_children()):\n",
        "            fuse_all_conv_bn(module)\n",
        "\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            if isinstance(stack[-1][1], nn.Conv2d):\n",
        "                setattr(model, stack[-1][0], fuse_conv_bn_eval(stack[-1][1], module))\n",
        "                setattr(model, name, nn.Identity())\n",
        "        else:\n",
        "            stack.append((name, module))\n",
        "\n",
        "net.eval()\n",
        "fuse_all_conv_bn(net)\n",
        "\n",
        "#Save the model for double training\n",
        "PATH = './mnist_net_collapsed.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tFjboFMs6hT"
      },
      "source": [
        "#### Collapsed SLAF-R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4UO-E6Zs-kD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # initialize alphai\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new) #\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, 13, 13, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 1)\n",
        "        self.fcnew = nn.Linear(3380, hidden)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          _ = self.fcnew.weight.copy_ (weight)\n",
        "          _ = self.fcnew.bias.copy_ (bias)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fcnew(x)\n",
        "        x = self.slu(x, 100)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPoridYqB7Wf"
      },
      "source": [
        "#### Weights control commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d000WsJwdBe"
      },
      "outputs": [],
      "source": [
        "print(dict(net_dos.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0mezeeUjRqQ"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net_collapsed.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owHjpvQX6QH0"
      },
      "source": [
        "### CNN2-SLAF-P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqvqxnPtMdCZ"
      },
      "source": [
        "Polynomial Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "5-6hev2j6Q2c",
        "outputId": "e950d21e-c2fa-4e54-fb5f-6debd6896d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROXIMATING BY LEAST SQUARES ...\n",
            "[-8.43752578e-04  2.81249562e-01  4.68762422e-06 -2.18749234e-03]\n",
            "WRITING IN F1 y CONV FILES ...\n",
            "           3             2\n",
            "-0.002187 x + 4.688e-06 x + 0.2812 x - 0.0008438\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efbb34b68f0>]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "GRADO = 3\n",
        "\n",
        "def sign(x_my):\n",
        "  if x_my > 0:\n",
        "    return 1\n",
        "  elif x_my < 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def comparison(enc_x):\n",
        "    return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "z_my = np.arange(-10, 10, 0.01)\n",
        "y_my = np.sign(z_my)\n",
        "\n",
        "LEAST_SQUARES = 0\n",
        "COMPOSITION = 1\n",
        "CHEBYSHEV = 2\n",
        "NEWTHON = 3\n",
        "FOURIER = 4\n",
        "\n",
        "SELECTION = LEAST_SQUARES\n",
        "\n",
        "if SELECTION == LEAST_SQUARES:\n",
        "    print(\"APPROXIMATING BY LEAST SQUARES ....\")\n",
        "    polynomial = np.polyfit(z_my, y_my, GRADO)\n",
        "    polynomial = polynomial[::-1]\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 y CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i].tolist()) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i].tolist()) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "elif SELECTION == CHEBYSHEV:\n",
        "    print(\"APPROXIMATING BY CHEBYSHEV\")\n",
        "    if GRADO == 3:\n",
        "        polynomial = [0, (7/3)*(1/10), 0, -(4/3)*(1/1000)]\n",
        "    else:\n",
        "        polynomial = [0, 1.2797, 0, -0.4444, 0, 0.2901 ,0, -0.2365, 0, 0.1111]\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 y CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "elif SELECTION == COMPOSITION:\n",
        "    print(\"APPROXIMATING BY COMPOSITION ....\")\n",
        "    if GRADO == 3:\n",
        "        polynomial = [0, (2126/1024)*(1/10), 0, (-1359/1024)*(1/1000)]\n",
        "    else:\n",
        "        f = np.poly1d([(-1/2), 0, (3/2),0])\n",
        "        g = np.poly1d([(-1359/1024), 0, (2126/1024),0])\n",
        "        polynomial = f(g)\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 y CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "elif SELECTION == NEWTHON:\n",
        "    print(\"APPROXIMATING BY NEWTON ....\")\n",
        "    polynomial = [0, (3/2)*(1/10), 0, (-1/2)*(1/1000)]\n",
        "    print(polynomial)\n",
        "    print(\"WRITING IN F1 y CONV FILES ....\")\n",
        "    f = open('f1.txt', 'w')\n",
        "    conv = open('conv.txt', 'w')\n",
        "    for i in range(GRADO + 1):\n",
        "        f.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "        conv.write('['+str(polynomial[i]) +']'+ '\\n')\n",
        "    f.close()\n",
        "    conv.close()\n",
        "\n",
        "## GRAPH THE POLYNOMIAL\n",
        "f = open('conv.txt', 'r')\n",
        "list_take=[]\n",
        "\n",
        "for i in range(GRADO + 1):\n",
        "    take = float(f.readline().replace('[','').replace(']',''))\n",
        "    list_take.append(take)\n",
        "f.close()\n",
        "\n",
        "list_take.reverse()\n",
        "poly_ = np.poly1d(list_take)\n",
        "print(poly_)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "poly_ff = [np.polyval(poly_, i) for i in z_my]\n",
        "\n",
        "ax.plot(z_my, poly_ff)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2 model using SLAF-P"
      ],
      "metadata": {
        "id": "E3b5pmuu8IAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGAN9C13NebC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "size_due_padding = 13\n",
        "input_due_padding = 200\n",
        "padding_conv1 = 1\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            f = open('f1.txt', 'r')\n",
        "            for i in range(alpha + 1):\n",
        "                next_value = float(f.readline().replace('[','').replace(']',''))\n",
        "                setattr(self, \"alpha\" + str(i), torch.tensor(next_value, device = device))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "            f.close()\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            f = open('conv.txt', 'r')\n",
        "            for i in range(alpha + 1):\n",
        "                next_value = float(f.readline().replace('[','').replace(']',''))\n",
        "                setattr(self, \"alpha\" + str(i), torch.tensor(next_value, device = device))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "            f.close()\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, size_due_padding, size_due_padding, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, padding_conv1)\n",
        "        for param in self.conv1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.batch1 = nn.BatchNorm2d(20)\n",
        "        for param in self.batch1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 0)\n",
        "        for param in self.conv2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc1 = nn.Linear(input_due_padding, hidden)\n",
        "        for param in self.fc1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.batch2 = nn.BatchNorm1d(100)\n",
        "        for param in self.batch2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        for param in self.fc2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        #ReLU using sign function approximations\n",
        "        x = (x + x*self.cslu(x))/2\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.batch2(x)\n",
        "        x = (x + x*self.slu(x, 100))/2\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXu-Vt4hNfUI"
      },
      "outputs": [],
      "source": [
        "print(net_dos.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfOqG7v8Nfmo"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net_.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos\n",
        "#OPTIONAL: net = nn.DataParallel(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yx6ft3dTo7H"
      },
      "source": [
        "#### Collapsing linear layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUK-Pzg8ToQY"
      },
      "outputs": [],
      "source": [
        "_ = torch.manual_seed (2023)\n",
        "# shape of intermediate \"input\" image\n",
        "in_channels = 20\n",
        "h = size_due_padding\n",
        "w = h\n",
        "\n",
        "#convolution parameters\n",
        "out_channels = 50\n",
        "kernel = 5\n",
        "stride = 1\n",
        "\n",
        "#fc paramaters\n",
        "in_features=int (out_channels * (((h - kernel) / 2) + 1)**2)\n",
        "in_features= input_due_padding\n",
        "out_features = 100\n",
        "\n",
        "#LAYERS DEFINITION\n",
        "#conv2 = torch.nn.Conv2d (in_channels, out_channels, kernel, stride)\n",
        "#fc1 = torch.nn.Linear (in_features, out_features)\n",
        "pool1 = nn.AvgPool2d(3, stride=2, padding=1) ##!!!!!!!!!!!!\n",
        "\n",
        "conv2 = net.conv2\n",
        "fc1 = net.fc1\n",
        "batch = net.batch2\n",
        "\n",
        "# create collapsed bias from conv2 and fc1\n",
        "bias = fc1 (torch.flatten (pool1(conv2 (pool1(torch.zeros (1, in_channels, h, w))))))\n",
        "bias = ((torch.sub(bias, batch.running_mean))/torch.sqrt(torch.add(batch.running_var, batch.eps))) * batch.weight + batch.bias\n",
        "\n",
        "# create collapsed weight from conv2 and fc1 (and bias)\n",
        "# batch of images, each with only a single pixel turned on\n",
        "n_pixels = in_channels * h * w   # number of pixels (including channels) in input image\n",
        "pixel_batch = torch.eye (n_pixels).reshape (n_pixels, in_channels, h, w)\n",
        "weight = (batch(fc1 (torch.flatten (pool1(conv2 (pool1(pixel_batch))), 1))) - bias).T\n",
        "\n",
        "# create collapsed Linear\n",
        "fcnew = torch.nn.Linear (n_pixels, out_features)   # Linear of correct shape\n",
        "\n",
        "# copy in collapsed weight and bias\n",
        "with torch.no_grad():\n",
        "  _ = fcnew.weight.copy_ (weight)\n",
        "  _ = fcnew.bias.copy_ (bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuugMY0jTrEP"
      },
      "source": [
        "#### Fusing convolutional and batch normalization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU0xNbtkTrL2"
      },
      "outputs": [],
      "source": [
        "def fuse_all_conv_bn(model):\n",
        "    stack = []\n",
        "    for name, module in model.named_children():\n",
        "        if list(module.named_children()):\n",
        "            fuse_all_conv_bn(module)\n",
        "\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            if isinstance(stack[-1][1], nn.Conv2d):\n",
        "                setattr(model, stack[-1][0], fuse_conv_bn_eval(stack[-1][1], module))\n",
        "                setattr(model, name, nn.Identity())\n",
        "        else:\n",
        "            stack.append((name, module))\n",
        "\n",
        "net.eval()\n",
        "fuse_all_conv_bn(net)\n",
        "\n",
        "PATH = './mnist_net_collapsed.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N5T4bnCpzYy"
      },
      "outputs": [],
      "source": [
        "print(net.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45uvgWk_Txse"
      },
      "source": [
        "#### Collapsed SLAF-P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hN5neACTwAW",
        "outputId": "b82448ab-3b70-4cf8-fabd-3b8dd792f638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
            "  (fcnew): Linear(in_features=3380, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (slu): soft_poly()\n",
            "  (cslu): conv_soft_poly()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device)) # create a tensor out of alpha\n",
        "        else:\n",
        "            f = open('f1.txt', 'r')\n",
        "            for i in range(alpha + 1):\n",
        "                next_value = float(f.readline())\n",
        "                setattr(self, \"alpha\" + str(i), torch.tensor(next_value, device = device))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True) # set requiresGrad to true!\n",
        "            f.close()\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)  # create a tensor out of alpha\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            f = open('conv.txt', 'r')\n",
        "            for i in range(alpha + 1):\n",
        "                next_value = float(f.readline())\n",
        "                setattr(self, \"alpha\" + str(i), torch.tensor(next_value, device = device))\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "            f.close()\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, size_due_padding, size_due_padding, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)  # create a tensor out of alpha\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, padding_conv1)\n",
        "        self.fcnew = nn.Linear(3380, hidden) #2880\n",
        "\n",
        "        with torch.no_grad():\n",
        "          _ = self.fcnew.weight.copy_ (weight)\n",
        "          _ = self.fcnew.bias.copy_ (bias)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = (x + x*self.cslu(x))/2\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fcnew(x)\n",
        "        x = (x + x*self.slu(x, 100))/2\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8gjS6kT7UN"
      },
      "source": [
        "#### Weights control commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bpCvYijT7xO"
      },
      "outputs": [],
      "source": [
        "print(dict(net.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEe4TuoST9gu"
      },
      "outputs": [],
      "source": [
        "print(net_dos.fcnew.weight.data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "122BYIOEUBtW"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net_collapsed.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iomUWfrSDQwg"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net_.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jPjwzD-5iWj"
      },
      "source": [
        "### CNN2-ReLU (without padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVDRWGjV5m9x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "onecycle=1\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 0)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.batch1 = nn.BatchNorm2d(20)\n",
        "        self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 0)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        self.fc1 = nn.Linear(50, 100)\n",
        "        self.batch2 = nn.BatchNorm1d(100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.batch2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "summary(net, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9407oVq7_hX"
      },
      "source": [
        "### CNN2-SLAF-R (without padding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdDtqVcP7_kl"
      },
      "source": [
        "1. Train CNN with ReLU (above)\n",
        "2. Re-train with SLAF-R; weights are fixed using requires_grad = False\n",
        "3. Collapse retrained model\n",
        "4. Test collapsed model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIFgHEfw8Ph-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # initialize alphai\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, 12, 12, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 0)\n",
        "        for param in self.conv1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.batch1 = nn.BatchNorm2d(20)\n",
        "        for param in self.batch1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 0)\n",
        "        for param in self.conv2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc1 = nn.Linear(50, hidden)\n",
        "        for param in self.fc1.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.batch2 = nn.BatchNorm1d(100)\n",
        "        for param in self.batch2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        for param in self.fc2.parameters():\n",
        "            param.data.requires_grad = False\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.batch2(x)\n",
        "        x = self.slu(x, 100)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net_dos.to(device)\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzjAy3Oa9KSZ"
      },
      "outputs": [],
      "source": [
        "print(dict(net.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGgkKM8y9Om9"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmoz-i0t9S58"
      },
      "source": [
        "#### Collapsing linear layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u7bd3gd9T2t"
      },
      "outputs": [],
      "source": [
        "_ = torch.manual_seed (2023)\n",
        "# shape of intermediate \"input\" image\n",
        "in_channels = 20\n",
        "h = 12\n",
        "w = h\n",
        "\n",
        "#convolution parameters\n",
        "out_channels = 50\n",
        "kernel = 5\n",
        "stride = 1\n",
        "\n",
        "#fc paramaters\n",
        "in_features=int (out_channels * (((h - kernel) / 2) + 1)**2)\n",
        "in_features= 50\n",
        "out_features = 100\n",
        "\n",
        "#LAYERS DEFINITION\n",
        "#conv2 = torch.nn.Conv2d (in_channels, out_channels, kernel, stride)\n",
        "#fc1 = torch.nn.Linear (in_features, out_features)\n",
        "pool1 = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "\n",
        "conv2 = net.conv2\n",
        "fc1 = net.fc1\n",
        "batch = net.batch2\n",
        "\n",
        "# create collapsed bias from conv2 and fc1\n",
        "bias = fc1 (torch.flatten (pool1(conv2 (pool1(torch.zeros (1, in_channels, h, w))))))\n",
        "bias = ((torch.sub(bias, batch.running_mean))/torch.sqrt(torch.add(batch.running_var, batch.eps))) * batch.weight + batch.bias\n",
        "\n",
        "# create collapsed weight from conv2 and fc1 (and bias)\n",
        "# batch of images, each with only a single pixel turned on\n",
        "n_pixels = in_channels * h * w   # number of pixels (including channels) in input image\n",
        "pixel_batch = torch.eye (n_pixels).reshape (n_pixels, in_channels, h, w)\n",
        "weight = (batch(fc1 (torch.flatten (pool1(conv2 (pool1(pixel_batch))), 1))) - bias).T\n",
        "\n",
        "# create collapsed Linear\n",
        "fcnew = torch.nn.Linear (n_pixels, out_features)   # Linear of correct shape\n",
        "\n",
        "# copy in collapsed weight and bias\n",
        "with torch.no_grad():\n",
        "  _ = fcnew.weight.copy_ (weight)\n",
        "  _ = fcnew.bias.copy_ (bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcJQlTQX9ZQi"
      },
      "source": [
        "#### Fusing convolutional and batch normalization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJkS5Dgk9ouu"
      },
      "outputs": [],
      "source": [
        "def fuse_all_conv_bn(model):\n",
        "    stack = []\n",
        "    for name, module in model.named_children():\n",
        "        if list(module.named_children()):\n",
        "            fuse_all_conv_bn(module)\n",
        "\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            if isinstance(stack[-1][1], nn.Conv2d):\n",
        "                setattr(model, stack[-1][0], fuse_conv_bn_eval(stack[-1][1], module))\n",
        "                setattr(model, name, nn.Identity())\n",
        "        else:\n",
        "            stack.append((name, module))\n",
        "\n",
        "net.eval()\n",
        "fuse_all_conv_bn(net)\n",
        "\n",
        "#Save the model for double training\n",
        "PATH = './mnist_net_collapsed.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpO8gRim9wSx"
      },
      "source": [
        "#### Collapsed SLAF-R (without padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5FWKee29w0V",
        "outputId": "03c4c321-c5ea-4f5a-dc6c-f6ff0edd2dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(2, 2))\n",
            "  (fcnew): Linear(in_features=2880, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (slu): soft_poly()\n",
            "  (cslu): conv_soft_poly()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device)) # create a tensor out of alpha\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new) # create a tensor out of alpha\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True) # set requiresGrad to true!\n",
        "\n",
        "\n",
        "    def forward(self, x, size):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), size, device = device)\n",
        "        f = open('f1.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # initialize alphai\n",
        "        if alpha == None:\n",
        "            self.alpha = nn.Parameter(torch.tensor(1000,64, device = device))\n",
        "        else:\n",
        "            for i in range(alpha + 1):\n",
        "                tensor_new = torch.nn.Parameter(torch.zeros(1, device = device))\n",
        "                setattr(self, \"alpha\" + str(i), tensor_new)\n",
        "                setattr(self, \"alpha\" + str(i) + \".requiresGrad\", True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ar_al = torch.zeros(self.alpha + 1, len(x), 20, 12, 12, device=device)\n",
        "        f = open('conv.txt', 'w')\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = getattr(self, \"alpha\" + str(i))\n",
        "            ar_al[i] = temp * (x**i)\n",
        "            f.write(str(temp.data.tolist()) + '\\n')\n",
        "        f.close()\n",
        "        return torch.sum(ar_al, dim=0)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=100, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 0)\n",
        "        self.fcnew = nn.Linear(2880, hidden)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          _ = self.fcnew.weight.copy_ (weight)\n",
        "          _ = self.fcnew.bias.copy_ (bias)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        self.slu = soft_poly(hidden, alpha=3)\n",
        "        self.cslu = conv_soft_poly(hidden, alpha=3)\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.cslu(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fcnew(x)\n",
        "        x = self.slu(x, 100)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net_dos = ConvNet()\n",
        "\n",
        "print(net_dos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWxJV_dW-ELv"
      },
      "source": [
        "#### Weights control commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0yqmGSS-IRn"
      },
      "outputs": [],
      "source": [
        "print(dict(net_dos.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os9-LJhE-Irm"
      },
      "outputs": [],
      "source": [
        "print(net_dos.fcnew.weight.data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz524QfN-IxD"
      },
      "outputs": [],
      "source": [
        "PATH = './mnist_net_collapsed.pth'\n",
        "net_dos.load_state_dict(torch.load(PATH), strict=False)\n",
        "net = net_dos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJodE-jYTEQL"
      },
      "source": [
        "### CryptoNets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwz5eQpNu0xN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 1)\n",
        "        self.pool1 = nn.AvgPool2d(3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, (2, 2), 0)\n",
        "        self.fc1 = nn.Linear(1250, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        #Use x = x * x for CNN-HE\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "summary(net, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoW4_TXsN-m7"
      },
      "source": [
        "#### Collapsing linear layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er7nVBtNN7R6"
      },
      "outputs": [],
      "source": [
        "_ = torch.manual_seed (2023)\n",
        "# shape of intermediate \"input\" image\n",
        "in_channels = 20\n",
        "h = 13\n",
        "w = h\n",
        "\n",
        "#convolution parameters\n",
        "out_channels = 50\n",
        "kernel = 5\n",
        "stride = 2\n",
        "\n",
        "#fc paramaters\n",
        "in_features=int (out_channels * (((h - kernel) / 2) + 1)**2)\n",
        "out_features = 100\n",
        "\n",
        "#LAYERS DEFINITION\n",
        "#conv2 = torch.nn.Conv2d (in_channels, out_channels, kernel, stride)\n",
        "#fc1 = torch.nn.Linear (in_features, out_features)\n",
        "pool1 = nn.AvgPool2d(3, stride=1, padding=1) ##!!!!!!!!!!!!\n",
        "\n",
        "conv2 = net.conv2\n",
        "fc1 = net.fc1\n",
        "\n",
        "# create collapsed bias from conv2 and fc1\n",
        "bias = fc1 (torch.flatten (pool1(conv2 (pool1(torch.zeros (1, in_channels, h, w))))))\n",
        "\n",
        "# create collapsed weight from conv2 and fc1 (and bias)\n",
        "# batch of images, each with only a single pixel turned on\n",
        "n_pixels = in_channels * h * w   # number of pixels (including channels) in input image\n",
        "pixel_batch = torch.eye (n_pixels).reshape (n_pixels, in_channels, h, w)\n",
        "weight = (fc1 (torch.flatten (pool1(conv2 (pool1(pixel_batch))), 1)) - bias).T\n",
        "\n",
        "# create collapsed Linear\n",
        "fcnew = torch.nn.Linear (n_pixels, out_features)   # Linear of correct shape\n",
        "\n",
        "# copy in collapsed weight and bias\n",
        "with torch.no_grad():\n",
        "  _ = fcnew.weight.copy_ (weight)\n",
        "  _ = fcnew.bias.copy_ (bias)\n",
        "\n",
        "# check on example batch of images\n",
        "input = torch.randn (5, in_channels, h, w)\n",
        "out_two_layer = fc1 (torch.flatten (conv2 (input), 1))\n",
        "out_collapsed = fcnew (torch.flatten (input, 1))\n",
        "\n",
        "torch.allclose (out_collapsed, out_two_layer, atol = 1.e-5)\n",
        "\n",
        "global_weight = weight\n",
        "global_bias = bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3VYS3zPOAom"
      },
      "source": [
        "#### Collapsed CryptoNets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGZ6b_QUVm2C"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 1)\n",
        "        self.pool1 = nn.AvgPool2d(3, stride=1, padding=1)\n",
        "        self.fcnew = nn.Linear(3380, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          _ = self.fcnew.weight.copy_ (weight)\n",
        "          _ = self.fcnew.bias.copy_ (bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fcnew(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net2 = Net()\n",
        "print(net2)\n",
        "summary(net2, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KpcOz4ROG9C"
      },
      "source": [
        "#### Weights control commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZugzHycdH5CB",
        "outputId": "db92916f-6e0d-4fc0-fdc2-97a6bd1328cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0050)\n"
          ]
        }
      ],
      "source": [
        "print(net2.fcnew.weight.data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_AVr7yRLMWi",
        "outputId": "994b8c9c-2c33-4670-9f1c-50908ccc12dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net.load_state_dict(torch.load('./mnist_net.pth'), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9x1x1IuLmo-"
      },
      "outputs": [],
      "source": [
        "net2.load_state_dict(torch.load('./mnist_net.pth'), strict=False)\n",
        "net = net2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42OBesPJbPsU"
      },
      "source": [
        "## One-Cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qwgn0y918Cxu"
      },
      "outputs": [],
      "source": [
        "def find_lr(model, optimiser, start_val = 1e-6, end_val = 1, beta = 0.99, loader = train_loader):\n",
        "    n = len(loader) - 1\n",
        "    factor = (end_val / start_val)**(1/n)\n",
        "    lr = start_val\n",
        "    optimiser.param_groups[0]['lr'] = lr\n",
        "    avg_loss, loss, acc = 0., 0., 0.\n",
        "    lowest_loss = 0.\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "    accuracies = []\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = model.to(device=device)\n",
        "    for i, (x, y) in enumerate(loader, start=1):\n",
        "        x = x.to(device = device, dtype = torch.float32)\n",
        "        y = y.to(device = device, dtype = torch.long)\n",
        "        optimiser.zero_grad()\n",
        "        scores = model(x)\n",
        "        cost = F.cross_entropy(input=scores, target=y)\n",
        "        loss = beta*loss + (1-beta)*cost.item()\n",
        "\n",
        "        avg_loss = loss/(1 - beta**i)\n",
        "\n",
        "        acc_ = ((torch.argmax(scores, dim=1) == y).sum()/scores.size(0))\n",
        "        if i > 1 and avg_loss > 4 * lowest_loss:\n",
        "            print(f'from here{i, cost.item()}')\n",
        "            return log_lrs, losses, accuracies\n",
        "        if avg_loss < lowest_loss or i == 1:\n",
        "            lowest_loss = avg_loss\n",
        "\n",
        "        accuracies.append(acc_.item())\n",
        "\n",
        "        losses.append(avg_loss)\n",
        "        log_lrs.append(lr)\n",
        "\n",
        "        cost.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        print(f'cost:{cost.item():.4f}, lr: {lr:.4f}, acc: {acc_.item():.4f}')\n",
        "        lr *= factor\n",
        "        optimiser.param_groups[0]['lr'] = lr\n",
        "\n",
        "    return log_lrs, losses, accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmUFNjUvBGYW"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDHHC0keNd25"
      },
      "outputs": [],
      "source": [
        "#ADAM\n",
        "import torch.optim as optim\n",
        "onecycle = 0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoJiuuLSjusD",
        "outputId": "bbbc7b9b-de0a-4001-80f5-30d71ae967e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With One-Cycle\n"
          ]
        }
      ],
      "source": [
        "#SGD with One-cycle\n",
        "import torch.optim as optim\n",
        "onecycle =1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if onecycle==1:\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.95, weight_decay=1e-4)\n",
        "  print(\"With One-Cycle\")\n",
        "else:\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "  print(\"Without One-Cycle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1AgjrhBThOB"
      },
      "outputs": [],
      "source": [
        "lg_lr, losses, accuracies = find_lr(net, optimizer, start_val=1e-6, end_val=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rLR3-v3Uq5P"
      },
      "outputs": [],
      "source": [
        "f1, ax1 = plt.subplots(figsize=(20,10))\n",
        "ax1.plot(lg_lr, losses)\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_xticks([1e-1, 2e-1, 1, 10])\n",
        "ax1.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRPIwEW_cHj4"
      },
      "outputs": [],
      "source": [
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
        "                                                max_lr=2e-1,\n",
        "                                                steps_per_epoch=len(train_loader),\n",
        "                                                epochs = 30, pct_start=0.43,\n",
        "                                                div_factor=10,\n",
        "                                                final_div_factor=1000,\n",
        "                                                three_phase=True, verbose=False\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UQSU_TaRAKU",
        "outputId": "1cc5e8c2-446d-4c28-f881-aa3c181203d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVFn0PiEhy4W"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs=30):\n",
        "    model.train()\n",
        "\n",
        "    if onecycle == 1:\n",
        "      print(\"With One-Cycle\")\n",
        "    else:\n",
        "      print(\"Without One-Cycle\")\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        correct_new = 0\n",
        "        total_new = 0\n",
        "        for data, target in train_loader:\n",
        "            if torch.cuda.is_available():\n",
        "              data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total_new += target.size(0)\n",
        "            correct_new += (predicted == target).sum().item()\n",
        "\n",
        "            #One-cycle\n",
        "            if onecycle == 1:\n",
        "              scheduler.step()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        acc_new = 100 * correct_new / total_new\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tCorrect: {} \\tAccuracy: {:.3f}'.format(epoch, train_loss, correct_new, acc_new))\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZY66ulZiIbW"
      },
      "outputs": [],
      "source": [
        "net = train(net, train_loader, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ7y3aIVtAhp"
      },
      "outputs": [],
      "source": [
        "#Save the model for re-training\n",
        "PATH = './mnist_net_.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6fblbIaOa6r"
      },
      "outputs": [],
      "source": [
        "print(check[0])\n",
        "print(check2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSdXvXSlkASy"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp4lNby6kmtO"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuVYhA5UkrDl"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC7nM-1uaay9"
      },
      "source": [
        "## Plaintext testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1f9Xys_Yfyl"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    model.eval()\n",
        "    j = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prQm_gm2ZdRk",
        "outputId": "65d4b9c3-bba4-4ff5-aa9f-652219f5ae03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.021133\n",
            "\n",
            "Test Accuracy of 0: 99% (978/980)\n",
            "Test Accuracy of 1: 99% (1130/1135)\n",
            "Test Accuracy of 2: 99% (1026/1032)\n",
            "Test Accuracy of 3: 99% (1004/1010)\n",
            "Test Accuracy of 4: 99% (978/982)\n",
            "Test Accuracy of 5: 99% (886/892)\n",
            "Test Accuracy of 6: 99% (949/958)\n",
            "Test Accuracy of 7: 99% (1021/1028)\n",
            "Test Accuracy of 8: 99% (968/974)\n",
            "Test Accuracy of 9: 99% (999/1009)\n",
            "\n",
            "Test Accuracy (Overall): 99% (9939/10000)\n",
            "2467.928647994995\n"
          ]
        }
      ],
      "source": [
        "t_start = time()\n",
        "test(net, test_loader, criterion)\n",
        "t_end = time()\n",
        "t_total = (t_end - t_start)*1000\n",
        "print(t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-OUXdqZssaz",
        "outputId": "6313601b-58c7-480b-c6f2-314da3c22df4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
              "  (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
              "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (batch2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  (slu): soft_poly()\n",
              "  (cslu): conv_soft_poly()\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOukZgWaDmgq"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'{classname:5s} is {accuracy:.2f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAMRNOnKkim5"
      },
      "source": [
        "# Ciphertext testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYVJmeSamzHh"
      },
      "source": [
        "COPY F1 and CONV1 to ciphertext files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl6_akRZTKpQ"
      },
      "source": [
        "# CNN2-HE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm5tr1igHbV0"
      },
      "source": [
        "## CNN2-HE-SLAF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH_nWz1J93ry",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "It's a PyTorch-like model using operations implemented in TenSEAL.\n",
        "    - .mm() method is doing the vector-matrix multiplication explained above.\n",
        "    - you can use + operator to add a plain vector as a bias.\n",
        "    - .conv2d_im2col() method is doing a single convlution operation.\n",
        "    - .square_() just square the encrypted vector inplace.\n",
        "\"\"\"\n",
        "\n",
        "class enc_conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context, torch.zeros(1, device = device))\n",
        "        f = open('t_conv.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            ar_al = ar_al + (x**i)*t[i]\n",
        "        return ar_al\n",
        "\n",
        "class enc_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context,torch.zeros(1, device=device))\n",
        "        f = open('t_f1.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = (x**i) * t[i]\n",
        "            ar_al = ar_al + temp\n",
        "        return ar_al\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fcnew_weight = torch_nn.fcnew.weight.T.data.tolist()\n",
        "        self.fcnew_bias = torch_nn.fcnew.bias.data.tolist()\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "        self.slu = enc_soft_poly(100, alpha=3)\n",
        "        self.cslu = enc_conv_soft_poly(10, alpha=3)\n",
        "\n",
        "    def forward(self, enc_x, windows_nb, context):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        enc_x = self.cslu(enc_x, context)\n",
        "        # fcnew layer\n",
        "        enc_x = enc_x.mm(self.fcnew_weight) + self.fcnew_bias\n",
        "        enc_x = self.slu(enc_x,  context)\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride, prog):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    j = 0\n",
        "    n_n = [0] * 10000\n",
        "    n_n_d = [0] * 10000\n",
        "    for data, target in test_loader:\n",
        "        j = j + 1\n",
        "        start_time = time()\n",
        "        # Encoding and encryption\n",
        "        dat = F.pad(data, (1, 1, 1, 1))\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, dat.view(30, 30).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        start_time = time()\n",
        "        enc_output = enc_model(x_enc, windows_nb, context)\n",
        "        n_n[j-1] = (time() - start_time)\n",
        "        print(\"only one test time: \",\"--- %s seconds ---\" % (time() - start_time))\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "        n_n_d[j-1] = (time() - start_time)\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test without decrypt \") + str(i) + str(\" time: : \") + str(n_n[i]) + str('\\n'))\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test with decrypt \") + str(i) + str(\" time: : \") + str(n_n_d[i]) + str('\\n'))\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "        prog.write(str( f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% ') + str(f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'))\n",
        "\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "    prog.write(str( f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ') + str(f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'))\n",
        "\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = net.conv1.kernel_size\n",
        "stride = net.conv1.stride[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtLpYGKvEsqy"
      },
      "outputs": [],
      "source": [
        "bits_scale = 26\n",
        "\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=16384,\n",
        "    coeff_mod_bit_sizes=[40, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 40]\n",
        ")\n",
        "\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u2AjutyfEuep"
      },
      "outputs": [],
      "source": [
        "enc_model = EncConvNet(net)\n",
        "\n",
        "prog = open('tests.txt', 'w', encoding='utf-8')\n",
        "t_time = time()\n",
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride, prog)\n",
        "print(\"full time process: \",\"--- %s seconds ---\" % (time()- t_time))\n",
        "prog.write(str(\"full time process: \") + str((time() - t_time)))\n",
        "prog.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-giqA_5_mBG"
      },
      "source": [
        "## CNN2-HE-SLAF (with ReLU = x + x * sign(x)*/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KVAz_px_vKF"
      },
      "outputs": [],
      "source": [
        "class enc_conv_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_conv_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context, torch.zeros(1, device = device))\n",
        "        f = open('t_conv.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            ar_al = ar_al + (x**i)*t[i]\n",
        "        return ar_al\n",
        "\n",
        "class enc_soft_poly(torch.nn.Module):\n",
        "    def __init__(self, in_features, alpha = None):\n",
        "        super(enc_soft_poly,self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        ar_al = ts.ckks_vector(context,torch.zeros(1, device=device))\n",
        "        f = open('t_f1.txt', 'r')\n",
        "        l = [line.strip() for line in f]\n",
        "        t = [float(item) for item in l]\n",
        "        for i in range(self.alpha + 1):\n",
        "            temp = (x**i) * t[i]\n",
        "            ar_al = ar_al + temp\n",
        "        return ar_al\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fcnew_weight = torch_nn.fcnew.weight.T.data.tolist()\n",
        "        self.fcnew_bias = torch_nn.fcnew.bias.data.tolist()\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "        self.slu = enc_soft_poly(100, alpha=3)\n",
        "        self.cslu = enc_conv_soft_poly(10, alpha=3)\n",
        "        self.dos_plaintext = [0.5] * 3380 #2880 (w/o padding) and 3380 (standard)\n",
        "        self.dos_plaintext_ = [0.5] * 100\n",
        "\n",
        "    def forward(self, enc_x, windows_nb, context):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        enc_x = (enc_x + enc_x * self.cslu(enc_x, context)) * self.dos_plaintext\n",
        "        # fcnew layer\n",
        "        enc_x = enc_x.mm(self.fcnew_weight) + self.fcnew_bias\n",
        "        #sign and ReLU equivalence\n",
        "        enc_x = (enc_x + enc_x * self.slu(enc_x,  context)) * self.dos_plaintext_\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride, prog):\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    j = 0\n",
        "    n_n = [0] * 10000\n",
        "    n_n_d = [0] * 10000\n",
        "    for data, target in test_loader:\n",
        "        j = j + 1\n",
        "        start_time = time()\n",
        "        # Encoding and encryption\n",
        "        dat = F.pad(data, (1, 1, 1, 1))\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, dat.view(30, 30).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        start_time = time()\n",
        "        enc_output = enc_model(x_enc, windows_nb, context)\n",
        "        n_n[j-1] = (time() - start_time)\n",
        "        print(\"only one test time: \",\"--- %s seconds ---\" % (time() - start_time))\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "        n_n_d[j-1] = (time() - start_time)\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test without decrypt \") + str(i) + str(\" time: : \") + str(n_n[i]) + str('\\n'))\n",
        "    for i in range (0, j-2):\n",
        "        prog.write(str(\"test with decrypt \") + str(i) + str(\" time: : \") + str(n_n_d[i]) + str('\\n'))\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "        prog.write(str( f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% ') + str(f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'))\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "    prog.write(str( f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ') + str(f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'))\n",
        "\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = net.conv1.kernel_size\n",
        "stride = net.conv1.stride[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pTI_cOS_vSV"
      },
      "outputs": [],
      "source": [
        "# Encryption Parameters\n",
        "bits_scale = 25\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=16384,\n",
        "        coeff_mod_bit_sizes=[40,bits_scale,bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 40]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_FmFvX9D_vYd"
      },
      "outputs": [],
      "source": [
        "enc_model = EncConvNet(net)\n",
        "\n",
        "prog = open('tests.txt', 'w', encoding='utf-8')\n",
        "start_time = time()\n",
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride, prog)\n",
        "print(\"full time process: \",\"--- %s seconds ---\" % (time() - start_time))\n",
        "prog.write(str(\"full time process: \") + str((time() - start_time)))\n",
        "prog.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}